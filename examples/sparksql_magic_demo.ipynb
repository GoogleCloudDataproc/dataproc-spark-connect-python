{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataprocSparkConnect SQL Magic Demo\n",
    "\n",
    "This notebook demonstrates how to use the Spark SQL magic commands with DataprocSparkSession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's create a DataprocSparkSession and load the magic extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a DataprocSparkSession (or use regular SparkSession for local testing)\n",
    "# For DataprocSparkSession:\n",
    "# spark = DataprocSparkSession.builder.getOrCreate()\n",
    "\n",
    "# For local testing with regular SparkSession:\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the Spark SQL magic extension\n%load_ext sparksql_magic"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "You can configure the default row display limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current configuration\n",
    "%config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default row limit to 30\n",
    "%config SparkSql.limit=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data\n",
    "\n",
    "Let's create some sample data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = [\n",
    "    (1, \"Alice\", 25, \"Engineering\"),\n",
    "    (2, \"Bob\", 30, \"Marketing\"),\n",
    "    (3, \"Charlie\", 35, \"Engineering\"),\n",
    "    (4, \"David\", 28, \"Sales\"),\n",
    "    (5, \"Eve\", 32, \"Marketing\"),\n",
    "    (6, \"Frank\", 29, \"Engineering\"),\n",
    "    (7, \"Grace\", 31, \"Sales\"),\n",
    "    (8, \"Henry\", 27, \"Marketing\")\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"age\", \"department\"]\n",
    "employees_df = spark.createDataFrame(data, columns)\n",
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "print(\"Sample data created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic SQL Query\n",
    "\n",
    "Execute a simple SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "SELECT * FROM employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "SELECT name, age, department \n",
    "FROM employees \n",
    "WHERE age > 30\n",
    "ORDER BY age DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Result in Variable\n",
    "\n",
    "Store the query result in a variable for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql engineers_df\n",
    "SELECT * FROM employees WHERE department = 'Engineering'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the engineers_df variable\n",
    "print(f\"Number of engineers: {engineers_df.count()}\")\n",
    "engineers_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Temporary View\n",
    "\n",
    "Create a new temporary view from a query result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql --view senior_employees\n",
    "SELECT * FROM employees WHERE age >= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "SELECT department, COUNT(*) as count \n",
    "FROM senior_employees \n",
    "GROUP BY department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache DataFrame\n",
    "\n",
    "Cache a DataFrame for better performance on repeated queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql --cache --view cached_data result_df\n",
    "SELECT \n",
    "    department,\n",
    "    AVG(age) as avg_age,\n",
    "    COUNT(*) as employee_count\n",
    "FROM employees\n",
    "GROUP BY department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Interpolation\n",
    "\n",
    "Use Python variables in SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age = 28\n",
    "target_department = \"Engineering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "SELECT * \n",
    "FROM employees \n",
    "WHERE age >= {min_age} \n",
    "  AND department = '{target_department}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override Display Limit\n",
    "\n",
    "Override the default display limit for a specific query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql --limit 3\n",
    "SELECT * FROM employees ORDER BY age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Caching\n",
    "\n",
    "Cache with eager loading for immediate execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql --eager dept_summary\n",
    "SELECT \n",
    "    department,\n",
    "    MIN(age) as min_age,\n",
    "    MAX(age) as max_age,\n",
    "    AVG(age) as avg_age\n",
    "FROM employees\n",
    "GROUP BY department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Query Example\n",
    "\n",
    "A more complex query with window functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "WITH ranked_employees AS (\n",
    "    SELECT \n",
    "        name,\n",
    "        age,\n",
    "        department,\n",
    "        ROW_NUMBER() OVER (PARTITION BY department ORDER BY age DESC) as rank_in_dept\n",
    "    FROM employees\n",
    ")\n",
    "SELECT * \n",
    "FROM ranked_employees \n",
    "WHERE rank_in_dept <= 2\n",
    "ORDER BY department, rank_in_dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Stop the Spark session when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}