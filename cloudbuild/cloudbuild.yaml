steps:
  # Build a container image which bakes in a source code snapshot and built
  # distribution artifacts.
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-container-image'
    args: ['build', '--tag=gcr.io/${PROJECT_ID}/google-spark-connect/google-spark-connect-presubmit', -f, 'cloudbuild/Dockerfile', '.']
  # Run all unit tests
  - name: 'gcr.io/${PROJECT_ID}/google-spark-connect/google-spark-connect-presubmit'
    id: 'run-unit-tests'
    waitFor: ['build-container-image']
    allowFailure: true
    entrypoint: 'pytest'
    args: ['-n', '10', 'tests/unit']
  # Run all integration tests. These exercise the actual API endpoints and
  # require credentials.
  - name: 'gcr.io/${PROJECT_ID}/google-spark-connect/google-spark-connect-presubmit'
    id: 'run-integration-tests'
    waitFor: ['build-container-image']
    allowFailure: true
    entrypoint: 'pytest'
    args: ['-n', '10', 'tests/integration']
    env:
      - 'GOOGLE_CLOUD_SUBNET=${_GOOGLE_CLOUD_SUBNET}'
      - 'GOOGLE_CLOUD_PROJECT=${_GOOGLE_CLOUD_PROJECT}'
      - 'GOOGLE_CLOUD_REGION=${_GOOGLE_CLOUD_REGION}'
  - name: 'gcr.io/${PROJECT_ID}/google-spark-connect/google-spark-connect-presubmit'
    id: 'verify-status'
    waitFor: ['run-unit-tests', 'run-integration-tests']
    entrypoint: '/opt/tests/cloudbuild/verify-status.sh'
    env:
      - 'BUILD_ID=${BUILD_ID}'
      - 'GOOGLE_CLOUD_PROJECT=${PROJECT_ID}'
timeout: 1800s
